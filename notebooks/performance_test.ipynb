{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute:  Normal =======================\n",
      "Recall:  0.9938197424892704\n",
      "Precision:  0.986873508353222\n",
      "F1 score:  0.9903344452998032\n",
      "False Negative Rate:  0.6180257510729614\n",
      "Attribute:  Thrief =======================\n",
      "Recall:  0.9868037703513282\n",
      "Precision:  0.9937866758715913\n",
      "F1 score:  0.9902829134061398\n",
      "False Negative Rate:  1.3196229648671807\n",
      "==========================================\n",
      "Macro-Precision:  0.9903300921124066\n",
      "Macro-Recall:  0.9903117564202992\n",
      "Macro-F1 Score:  0.9903086793529715\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_matrix_2 = np.array([[5789,36],\n",
    " [77,5758]])\n",
    "\n",
    "# List of attributes\n",
    "fab_attri = ['Normal', 'max_engine_coolant_temp_attack', 'fuzzing_attack', 'max_speedometer_attack',\n",
    "             'reverse_light_on_attack', 'reverse_light_off_attack', 'correlated_signal_attack']\n",
    "mas_attri = ['Normal', 'max_engine_coolant_temp_attack', 'max_speedometer_attack',\n",
    "             'reverse_light_on_attack', 'reverse_light_off_attack', 'correlated_signal_attack']\n",
    "\n",
    "attri = ['Normal','Thrief']\n",
    "\n",
    "# F1 score calculation for each attribute\n",
    "f1_scores = []\n",
    "\n",
    "\n",
    "def cal_cm(confusion_matrix, attributes):\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    for i in range(len(attributes)):\n",
    "        TP = confusion_matrix[i, i]\n",
    "        TN = sum(sum(confusion_matrix)) - TP\n",
    "        FP = sum(confusion_matrix[:, i]) - TP\n",
    "        FN = sum(confusion_matrix[i, :]) - TP\n",
    "        accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1_score = 2 * precision * recall / (precision + recall)\n",
    "        FNR = (FN / (TP + FN))*100  # False Negative Rate\n",
    "        FPR = (FP / (FP + TN))*100  # False Positive Rate\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1_score)\n",
    "        print('Attribute: ', attributes[i], '=======================')\n",
    "        print('Recall: ', recall)\n",
    "        print('Precision: ', precision)\n",
    "        print('F1 score: ', f1_score)\n",
    "        print('False Negative Rate: ', FNR)  # Print FNR\n",
    "    macro_precision = sum(precision_list) / len(precision_list)\n",
    "    macro_recall = sum(recall_list) / len(recall_list)\n",
    "    macro_f1_score = sum(f1_score_list) / len(f1_score_list)\n",
    "    print('==========================================')\n",
    "    print('Macro-Precision: ', macro_precision)\n",
    "    print('Macro-Recall: ', macro_recall)\n",
    "    print('Macro-F1 Score: ', macro_f1_score)\n",
    "    return macro_precision, macro_recall, macro_f1_score\n",
    "\n",
    "\n",
    "f1 = cal_cm(confusion_matrix_2, attri)\n",
    "\n",
    "# f1_scores_per_attribute = dict(zip(attributes, f1_scores))\n",
    "# f1_scores_per_attribute"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
